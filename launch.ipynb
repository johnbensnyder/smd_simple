{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "from sagemaker import analytics, image_uris\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    TensorBoardOutputConfig,\n",
    "    CollectionConfig,\n",
    "    ProfilerConfig,\n",
    "    FrameworkProfile,\n",
    "    DetailedProfilingConfig,\n",
    "    rule_configs,\n",
    "    ProfilerRule,\n",
    ")\n",
    "from smdebug.core.collection import CollectionKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "boto_sess = boto3.Session()\n",
    "sm = boto_sess.client('sagemaker')\n",
    "\n",
    "s3_bucket = \"s3://jbsnyder-sagemaker-us-east/\"\n",
    "\n",
    "base_job_name = \"jbsnyder-resnet-debugger\"\n",
    "date_str = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "time_str = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "job_name = f\"{base_job_name}-{time_str}\"\n",
    "\n",
    "output_path = os.path.join(s3_bucket, \"sagemaker-output\", date_str, job_name)\n",
    "code_location = os.path.join(s3_bucket, \"sagemaker-code\", date_str, job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_configs=[\n",
    "    CollectionConfig(\n",
    "        name=CollectionKeys.WEIGHTS,\n",
    "        parameters={\n",
    "            \"save_interval\": \"100\",\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "\n",
    "debugger_hook_config=DebuggerHookConfig(\n",
    "    collection_configs=collection_configs,   \n",
    ")\n",
    "\n",
    "rules = [\n",
    "Rule.sagemaker(\n",
    "        base_config=rule_configs.loss_not_decreasing(),\n",
    "        rule_parameters={\n",
    "                \"tensor_regex\": \".*\",\n",
    "                \"use_losses_collection\": \"True\",\n",
    "                \"num_steps\": \"10\",\n",
    "                \"diff_percent\": \"0.1\",\n",
    "                \"increase_threshold_percent\": \"5\",\n",
    "                \"mode\": \"GLOBAL\"\n",
    "        },\n",
    "        collections_to_save=[\n",
    "            CollectionConfig(\n",
    "                name=CollectionKeys.LOSSES,\n",
    "                parameters={\n",
    "                    \"save_interval\": \"10\",\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        actions=rule_configs.ActionList(rule_configs.Email(\"email@email.com\"))\n",
    "    ),\n",
    "Rule.sagemaker(\n",
    "        base_config=rule_configs.exploding_tensor(),\n",
    "        rule_parameters={\n",
    "                \"tensor_regex\": \".*gradient\",\n",
    "                \"only_nan\": \"False\"\n",
    "        },\n",
    "        collections_to_save=[ \n",
    "            CollectionConfig(\n",
    "                name=\"gradients\", \n",
    "                parameters={\n",
    "                    \"save_interval\": \"100\"\n",
    "                }\n",
    "            )\n",
    "        ],\n",
    "        actions=rule_configs.ActionList(rule_configs.Email(\"email@email.com\"))\n",
    "    ),\n",
    "ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "\n",
    "profiler_config=ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(\n",
    "        detailed_profiling_config=DetailedProfilingConfig(\n",
    "            start_step=50, \n",
    "            num_steps=10\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "tensorboard_output_config = TensorBoardOutputConfig(s3_output_path=os.path.join(output_path, 'tensorboard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"train_data_src\": os.path.join(s3_bucket, \"data\", \"imagenet\", \"train\"), # \"/opt/ml/input/data/train/\", \n",
    "                   \"val_data_src\": os.path.join(s3_bucket, \"data\", \"imagenet\", \"val\"), # \"/opt/ml/input/data/val/\", \n",
    "                   \"num_epochs\": 4,\n",
    "                   'learning_rate': 0.004,\n",
    "                   'batch_size': 512,\n",
    "                   'dataloader_workers': 12,\n",
    "                   'precision': 'float16',\n",
    "                   'dist': 'smddp',\n",
    "                   }\n",
    "\n",
    "distribution = { \"smdistributed\": { \"dataparallel\": { \"enabled\": True } } }\n",
    "entry_point = \"train.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p4d.24xlarge'\n",
    "instance_count = 2\n",
    "\n",
    "image_uri = image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    version='1.12',\n",
    "    py_version='py38',\n",
    "    image_scope='training',\n",
    "    instance_type=instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    source_dir=\"./src\",\n",
    "    entry_point=entry_point,\n",
    "    base_job_name=job_name,\n",
    "    role=get_execution_role(),\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    distribution=distribution,\n",
    "    volume_size=400,\n",
    "    max_run=7200,\n",
    "    hyperparameters=hyperparameters,\n",
    "    image_uri=image_uri,\n",
    "    output_path=os.path.join(output_path, 'training-output'),\n",
    "    checkpoint_s3_uri=os.path.join(output_path, 'training-checkpoints'),\n",
    "    model_dir=os.path.join(output_path, 'training-model'),\n",
    "    code_location=code_location,\n",
    "    ## Debugger parameters\n",
    "    enable_sagemaker_metrics=True,\n",
    "    rules=rules,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    profiler_config=profiler_config,\n",
    "    input_mode='File',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    inputs=None,\n",
    "    wait=False,\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.tensorboard_output_config.s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
